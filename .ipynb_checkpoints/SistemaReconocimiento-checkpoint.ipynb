{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de Reconocimento de Lenguaje de Señas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proyecto consiste en la realización de un sistema de aprendizaje de lenguaje de señas. En el cual el usuario mediante el uso de la aplicación podrá agilizar su aprendizaje en el área ya mencionada.\n",
    "\n",
    "Realizado por:\n",
    "    \n",
    "    Sebastián Medina\n",
    "    Diego Orellana\n",
    "    Jorge Peralta\n",
    "    Ronnie Urdiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toma de capturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_imagenes = 'Tensorflow/workspace/images/collectedimages'\n",
    "frases = ['hola', 'gracias', 'si', 'no', 'tequiero','A','E','I','O','U']\n",
    "num_img = 15 #numero de fotos a tomar\n",
    "\n",
    "# captura de fotos\n",
    "for frase in frases:\n",
    "    !mkdir {'Tensorflow\\workspace\\images\\collectedimages\\\\'+frase}\n",
    "    captura = cv2.VideoCapture(0)\n",
    "    print('Tomando fotos para {}'.format(frase))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(num_img):\n",
    "        ret, frame = captura.read()\n",
    "        imgname = os.path.join(ruta_imagenes, frase, frase+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    captura.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTA_TRABAJO = 'Tensorflow/workspace'\n",
    "RUTA_SCRIPTS = 'Tensorflow/scripts'\n",
    "RUTA_MODELO_API = 'Tensorflow/models'\n",
    "RUTA_ANOTACIONES = RUTA_TRABAJO+'/annotations'\n",
    "RUTA_IMAGENES = RUTA_TRABAJO+'/images'\n",
    "RUTA_MODELOS = RUTA_TRABAJO+'/models'\n",
    "RUTA_MODELOS_ENT = RUTA_TRABAJO+'/pre-trained-models'\n",
    "RUTA_CONF = RUTA_MODELOS+'/my_ssd_mobnet/pipeline.config'\n",
    "RUTA_CHECKPOINT = RUTA_MODELOS+'/my_ssd_mobnet/'\n",
    "NOMBRE_MODELO = 'my_ssd_mobnet' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Palabras a reconocer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'hola', 'id':1},\n",
    "         {'name':'si', 'id':2},\n",
    "         {'name':'no', 'id':3},\n",
    "         {'name':'gracias', 'id':4},\n",
    "         {'name':'tequiero', 'id':5},\n",
    "         {'name':'A', 'id':6},\n",
    "         {'name':'E', 'id':7},\n",
    "         {'name':'I', 'id':8},\n",
    "         {'name':'O', 'id':9},\n",
    "         {'name':'U', 'id':10}]\n",
    "\n",
    "with open(RUTA_ANOTACIONES + '\\label_map.pbtxt', 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- Creación de los modelos a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {RUTA_SCRIPTS + '/generate_tfrecord.py'} -x {RUTA_IMAGENES + '/train'} -l {RUTA_ANOTACIONES + '/label_map.pbtxt'} -o {RUTA_ANOTACIONES + '/train.record'}\n",
    "!python {RUTA_SCRIPTS + '/generate_tfrecord.py'} -x{RUTA_IMAGENES + '/test'} -l {RUTA_ANOTACIONES + '/label_map.pbtxt'} -o {RUTA_ANOTACIONES + '/test.record'}\n",
    "\n",
    "!mkdir {'Tensorflow\\workspace\\models\\\\' + NOMBRE_MODELO}\n",
    "!cp {RUTA_MODELOS_ENT+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'} {RUTA_MODELOS+'/'+NOMBRE_MODELO}\n",
    "\n",
    "!cd Tensorflow && git clone https://github.com/tensorflow/models #descarga de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.- Configuración preparatoria para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUTA_CONF = RUTA_MODELOS+'/'+NOMBRE_MODELO+'/pipeline.config'\n",
    "config = config_util.get_configs_from_pipeline_file(RUTA_CONF)\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(RUTA_CONF, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  \n",
    "    \n",
    "\n",
    "pipeline_config.model.ssd.num_classes = 5\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = RUTA_MODELOS_ENT+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= RUTA_ANOTACIONES + '/label_map.pbtxt'\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [RUTA_ANOTACIONES + '/train.record']\n",
    "pipeline_config.eval_input_reader[0].label_map_path = RUTA_ANOTACIONES + '/label_map.pbtxt'\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [RUTA_ANOTACIONES + '/test.record']\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(RUTA_CONF, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Generar comando para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=5000\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"python {}/research/object_detection/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config --num_train_steps=5000\"\"\".format(RUTA_MODELO_API, RUTA_MODELOS,NOMBRE_MODELO,RUTA_MODELOS,NOMBRE_MODELO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.- Carga del modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(RUTA_CONF)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(RUTA_CHECKPOINT, 'ckpt-6')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.- Funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(RUTA_ANOTACIONES+'/label_map.pbtxt')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=3,\n",
    "                min_score_thresh=.9,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('Sistema de reconocimiento de señas',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release() #finalizar sesión de la cámara"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
